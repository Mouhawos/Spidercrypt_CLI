# ğŸ›¡ï¸ Spidercrypt CLI â€” AI & Cybersecurity Security Toolkit

Spidercrypt CLI is an advanced cybersecurity tool designed to protect AI systems, ML pipelines, and applications against:

- Prompt injections
- Data poisoning
- Sensitive data leaks
- Malicious outputs
- Application vulnerabilities
- AI jailbreak attempts

It is designed for easy integration into enterprise environments.

---

## ğŸš€ Features

âœ” Source code analysis
âœ” Prompt injection detection
âœ” AI firewall (Prompt Firewall)
âœ” Sensitive data masking (PII)
âœ” Cleanup of dangerous outputs
âœ” Data poisoning detection
âœ” JSON report generation

---

## ğŸ“¦ Installation

### Prerequisites

- Python 3.11+
- Git

### Project cloning


git clone https://github.com/Mouhawos/Spidercrypt_CLI.git
cd Spidercrypt_CLI
Creating a virtual environment
Windows
python -m venv spidercrypt-venv
.\spidercrypt-venv\Scripts\activate
Linux / macOS
python3 -m venv spidercrypt-venv
source spidercrypt-venv/bin/activate
Installing dependencies
pip install -r requirements.txt
â–¶ï¸ Usage
Display available commands:

python cli.py
Result:

Commands:

check-prompt
data-ghosting
fingerprint
output-sanitizer
prompt-firewall
scan-code
detect-poisoning
ğŸ” Code Analysis
Analyzes a source file and generates a report.

python cli.py scan-code vulnerable_test.py --output audit.json
Result:

Analysis complete â†’ audit.json
ğŸ§  Prompt Injection Detection
python cli.py check-prompt prompt.txt
Example (attack detected)
{
"risk_score": 0.833,

"allowed": false,

"severity": "high"

}
ğŸ” AI Firewall
Automatically blocks dangerous prompts.

python cli.py prompt-firewall prompt.txt
Example:

ğŸš« Prompt blocked
ğŸ•µï¸ Sensitive Data Masking (PII)
python cli.py data-ghosting pii.txt --output ghosted.txt
Result:

â†’ Masked text saved
ğŸ§¹ Output Cleanup
Detects XSS, scripts, and injections.

python cli.py output-sanitizer output.txt
Example:

{
"status": "sanitized",

"risky_patterns": ["<script>"]

ğŸ§¬ Data Poisoning Detection
Analyzes ML datasets.

python cli.py detect-poisoning dataset.json
Example (attack detected)
{
"poisoning_detected": true,

"severity": "high"

}
âš ï¸ Data poisoning suspected
ğŸ“Š Score Interpretation
Level Significance
Low Low Risk
Medium Moderate Risk
High Critical Threat
ğŸ”§ CI/CD Integration
Spidercrypt CLI can be integrated into:

GitHub Actions

GitLab CI

Jenkins

MLOps Pipelines

Example GitHub Actions
- name: Scan Security
run: |
python cli.py scan-code app.py --output report.json
ğŸ¯ Use Cases
Securing Chatbots

AI SaaS Protection

ML Auditing

API Gateway

Autonomous Agents

Data Pipelines

Cloud Security

ğŸ“ Project Structure
Spidercrypt_CLI/
â”œâ”€â”€ cli.py
â”œâ”€â”€ engines/
â”œâ”€â”€ detectors/
â”œâ”€â”€ utils/
â”œâ”€â”€ reports/
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
ğŸ“Œ Best Practices
âœ” Scan user prompts
âœ” Verify datasets before training
âœ” Filter all outputs
âœ” Log reports
âœ” Automate Audits

ğŸ“„ License
This project is licensed under the MIT License.

See the LICENSE file for more information.

ğŸ‘¨â€ğŸ’» Author
Developed by Mouhamed Sow
Founder of Spidercrypt

ğŸ“§ Contact: support@spidercrypt.io
ğŸŒ Website: https://spidercrypt.io

â­ Support
If this project helps you:

Add a â­ on GitHub

Share it

Contribute

ğŸ› ï¸ Roadmap

Web Dashboard

REST API

Advanced ML Models

Real-Time Monitoring

Cloud Platform

Enterprise Version
